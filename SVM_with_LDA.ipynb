{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[400   0]\n",
      " [  1 399]]\n",
      "\n",
      "Sensitivity: 1.00\n",
      "Specificity: 1.00\n",
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Loading the dataset\n",
    "csv_file_path = 'wavelet_metrics.csv'  \n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Separating the features and labels\n",
    "X = data.drop(['Data', 'label'], axis=1)  \n",
    "y = data['label']  # Extract labels (0 or 1)\n",
    "\n",
    "class_0 = data[data['label'] == 0]\n",
    "class_1 = data[data['label'] == 1]\n",
    "\n",
    "# Split data for training and testing\n",
    "\n",
    "train_0, test_0 = train_test_split(class_0, test_size=0.5, random_state=0)\n",
    "train_1, test_1 = train_test_split(class_1, test_size=0.5, random_state=0)\n",
    "\n",
    "# Concatenated the training and testing data for both classes\n",
    "\n",
    "train_data = pd.concat([train_0, train_1])\n",
    "test_data = pd.concat([test_0, test_1])\n",
    "\n",
    "# Suffling the data\n",
    "train_data = train_data.sample(frac=1).reset_index(drop=True)\n",
    "test_data = test_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Extracting features and labels from the training and testing sets\n",
    "X_train = train_data.drop(['Data', 'label'], axis=1)\n",
    "y_train = train_data['label']\n",
    "X_test = test_data.drop(['Data', 'label'], axis=1)\n",
    "y_test = test_data['label']\n",
    "\n",
    "# Standardizing the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# LDA for dimensionality reduction\n",
    "lda = LDA(n_components=1)  # Binary classification, so 1 component is sufficient\n",
    "X_train_lda = lda.fit_transform(X_train, y_train)\n",
    "X_test_lda = lda.transform(X_test)\n",
    "\n",
    "#Training an SVM classifier on the LDA-transformed data\n",
    "svm = SVC( C = 1, kernel='rbf', random_state=0, gamma=0.02)  \n",
    "svm.fit(X_train_lda, y_train)\n",
    "\n",
    "# Predict and evaluate the SVM classifier\n",
    "y_pred = svm.predict(X_test_lda)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "# Calculate Sensitivity and Specificity\n",
    "sensitivity = tp / (tp + fn)  # True Positive Rate\n",
    "specificity = tn / (tn + fp)  # True Negative Rate\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(f\"\\nSensitivity: {sensitivity:.2f}\")\n",
    "print(f\"Specificity: {specificity:.2f}\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 112 candidates, totalling 1120 fits\n",
      "Best Parameters: {'C': 0.01, 'gamma': 0.5}\n",
      "Confusion Matrix:\n",
      "[[400   0]\n",
      " [  1 399]]\n",
      "\n",
      "Sensitivity: 1.00\n",
      "Specificity: 1.00\n",
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 2, 3, 5, 10, 11, 20, 30, 40, 50, 100, 200],      # Regularization parameter\n",
    "    'gamma': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3, 0.5, 1],  # RBF Kernel coefficient\n",
    "}\n",
    "\n",
    "# Use StratifiedKFold for balanced cross-validation splits\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "# Defiing the SVM with RBF kernel\n",
    "svm = SVC(kernel='rbf', random_state=0)\n",
    "\n",
    "# Perform GridSearchCV to find the optimal hyperparameters\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=cv, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train_lda, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Training the final SVM model with the best parameters\n",
    "best_svm = grid_search.best_estimator_\n",
    "best_svm.fit(X_train_lda, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_svm.predict(X_test_lda)\n",
    "\n",
    "# Calculating the confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "# Calculate Sensitivity and Specificity\n",
    "sensitivity = tp / (tp + fn)  # True Positive Rate\n",
    "specificity = tn / (tn + fp)  # True Negative Rate\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(f\"\\nSensitivity: {sensitivity:.2f}\")\n",
    "print(f\"Specificity: {specificity:.2f}\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
